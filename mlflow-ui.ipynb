{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "Copyright Psitron Technologies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtn_KT393oTv"
      },
      "source": [
        "#Setting up the API key and installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BV6CslQ35EC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"  # Replace with your actual key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xXR4euJpAZVd",
        "outputId": "d742d1d6-b7d3-40d9-cd1b-ad05ed3bf650"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow pandas datasets transformers anthropic pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJg5BSUx3-G2"
      },
      "source": [
        "Tracking URI: You need to make sure that Notebook 2 knows where to find the MLflow tracking server. If you're using a local tracking server (the default), and you started the tracking server in Notebook 1, then Notebook 2 also needs to point to http://localhost:5000. You can set the MLFLOW_TRACKING_URI environment variable in Notebook 2:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phjkmabeJCYY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://896e-35-204-243-208.ngrok-free.app\" #Put there your ngrok URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmfoaJBX44cs"
      },
      "source": [
        "self-contained code for just loading and wrapping the Claude model to MLflow, ready to be executed in a Colab notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T4PUUmbJ2Ox",
        "outputId": "a386526b-208e-4593-d4bc-d1b3d47ba4c8"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import os\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# 1. Define the ClaudeModelWrapper class\n",
        "class ClaudeModelWrapper(mlflow.pyfunc.PythonModel):\n",
        "    \"\"\"A custom MLflow model that wraps the Anthropic Claude API.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str, system_prompt: str):\n",
        "        self.model_name = model_name\n",
        "        self.system_prompt = system_prompt\n",
        "        self.anthropic_api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "\n",
        "    def load_context(self, context: mlflow.pyfunc.model.PythonModelContext) -> None:\n",
        "        \"\"\"Loads artifacts (none in this case).\"\"\"\n",
        "        if not self.anthropic_api_key:\n",
        "            raise ValueError(\"Anthropic API key not found. Set ANTHROPIC_API_KEY environment variable.\")\n",
        "\n",
        "    def predict(self, context: mlflow.pyfunc.model.PythonModelContext, model_input: pd.DataFrame) -> list[str]:\n",
        "        \"\"\"\n",
        "        Generates predictions using the Claude API.\n",
        "\n",
        "        Args:\n",
        "            context: MLflow context (unused).\n",
        "            model_input: Pandas DataFrame with a 'question' column containing prompts.\n",
        "\n",
        "        Returns:\n",
        "            List of responses from Claude.\n",
        "        \"\"\"\n",
        "        client = anthropic.Anthropic()\n",
        "        responses = []\n",
        "        for question in model_input[\"question\"]:\n",
        "            try:\n",
        "                message = client.messages.create(\n",
        "                    model=self.model_name,\n",
        "                    max_tokens=1024,\n",
        "                    system = self.system_prompt,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": question}\n",
        "                    ],\n",
        "                )\n",
        "                responses.append(message.content[0].text)\n",
        "            except Exception as e:\n",
        "                print(f\"Error calling Claude API: {e}\")\n",
        "                responses.append(None)  # Or a suitable error value\n",
        "        return responses\n",
        "\n",
        "# 2. Set up the Experiment and Tracking\n",
        "# (Optional, but recommended for organization)\n",
        "mlflow.set_experiment(\"claude_wrapping\")\n",
        "\n",
        "# 3. Run\n",
        "with mlflow.start_run() as run:\n",
        "    # 4. Define Claude Model and System Prompt\n",
        "    claude_model_name = \"claude-3-opus-20240229\"  # Or an appropriate Claude model. Change the model with one that is accesible\n",
        "    system_prompt = \"Answer the following question concisely.\"\n",
        "\n",
        "    # 5. Create the ClaudeModelWrapper Instance\n",
        "    claude_model = ClaudeModelWrapper(model_name=claude_model_name, system_prompt=system_prompt)\n",
        "\n",
        "    # 6. Log the MLflow Model\n",
        "    mlflow.pyfunc.log_model(\n",
        "        python_model=claude_model,\n",
        "        artifact_path=\"claude_model\",\n",
        "        input_example=pd.DataFrame({\"question\": [\"What is the capital of France?\"]}),\n",
        "    )\n",
        "\n",
        "    print(f\"Successfully logged Claude model to run: {run.info.run_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a95ffefc431349bdb9e1ee3e045d332a",
            "072421e892194abfa85cfb1995076ff3",
            "5c0fb845c473469b8511494888e03e71",
            "ac13c74a8fd94aa6a7dd110325daafc6",
            "7c5a5ee2a58344d3a26b1c7b0aa4ca0b",
            "6a1a68e5be33489a97408df998715056",
            "88f81ad09ab1475db5197d93babd41ba",
            "19048e71f5b145da8c401ab385531440",
            "b4536cfa5b9b4947b59dee5ee22bf4d5",
            "5122d9709c294b7191e81fd8d344448a",
            "2accc7cc15c440f8971532206d17dbc9"
          ]
        },
        "id": "T2s6mVDiMCKN",
        "outputId": "c7554396-3d60-4834-b92e-2d075d5e7a5b"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "import anthropic\n",
        "import os\n",
        "\n",
        "# 1. Install Dependencies (Run this cell once if you haven't already)\n",
        "!pip install mlflow anthropic pandas\n",
        "\n",
        "# 2. Set Your Anthropic API Key (Replace with your actual key!)\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"  # Replace!\n",
        "\n",
        "# 3. Configuration\n",
        "# 4. Define your model run ID\n",
        "model_run_id = \"58868c4b1e1a424d9fb7433a76f2ac0d\"\n",
        "\n",
        "# Set your model and experiment name\n",
        "claude_model_name = \"claude-3-opus-20240229\" # @param {type:\"string\"}\n",
        "MLFLOW_EXPERIMENT_NAME = \"claude_wrapping\" # @param {type:\"string\"}\n",
        "\n",
        "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
        "\n",
        "# Check is the api key is accesible\n",
        "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
        "  raise ValueError(\"Anthropic API key not found. Set ANTHROPIC_API_KEY environment variable.\")\n",
        "\n",
        "# 5. Load the Model (Replace with the correct Model URI)\n",
        "model_uri = 'runs:/58868c4b1e1a424d9fb7433a76f2ac0d/claude_model'\n",
        "loaded_model = mlflow.pyfunc.load_model(model_uri) # Load only once, to save in the test.\n",
        "\n",
        "# 6. Define the evaluation Function\n",
        "def get_claude_judgment(question, answer, ground_truth, prompt, claude_model_id):\n",
        "  \"\"\"Calls Claude API for evaluation and returns a tuple (score, justification) or (1, \"Error\") on error.\"\"\"\n",
        "  try:\n",
        "      client = anthropic.Anthropic()\n",
        "      message = client.messages.create(\n",
        "          model=claude_model_id,\n",
        "          max_tokens=300,\n",
        "          system=prompt,\n",
        "          messages=[{\"role\": \"user\", \"content\": f\"Question: {question}\\nAnswer: {answer}\\nGround Truth: {ground_truth}\"}],\n",
        "      )\n",
        "      claude_response = message.content[0].text\n",
        "      try:  # Safely extract score and justification\n",
        "          score = int(claude_response.split()[0])\n",
        "          justification = \" \".join(claude_response.split()[1:])\n",
        "          return score, justification\n",
        "      except (ValueError, IndexError):\n",
        "          print(f\"Could not parse Claude's response: {claude_response}\")  # More specific message\n",
        "          return 1, \"Could not parse Claude's response.\"\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Error calling Claude API: {e}\")\n",
        "      return 1, \"Error during evaluation.\"  # Consistent return\n",
        "\n",
        "\n",
        "def claude_evaluate(model, data, claude_model_id):\n",
        "  question = data[\"question\"].tolist()\n",
        "  answers = model.predict(data)\n",
        "  ground_truth = data[\"ground_truth\"].tolist()\n",
        "  scores = []\n",
        "  justifications = []\n",
        "\n",
        "  for index in range(len(data)):\n",
        "    score, justification = get_claude_judgment(question = question[index], answer = answers[index], ground_truth = ground_truth[index], prompt = \"You will score from 1 to 5 the answer, comparing it with the Ground Truth\", claude_model_id = claude_model_id)\n",
        "    scores.append(score)\n",
        "    justifications.append(justification)\n",
        "\n",
        "  result = sum(scores)/len(scores)\n",
        "\n",
        "  return {\"score\":result}\n",
        "\n",
        "# 7. Define Evaluation Data\n",
        "eval_data = pd.DataFrame({\n",
        "    \"question\": [\n",
        "        \"What is MLflow?\",\n",
        "        \"What is Spark?\",\n",
        "    ],\n",
        "    \"ground_truth\": [\n",
        "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle.\",\n",
        "        \"Apache Spark is a fast, general-purpose cluster computing system for big data processing.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# 8. Evaluate the Model\n",
        "try:\n",
        "  with mlflow.start_run() as run: #Create a run for this\n",
        "    results = claude_evaluate(loaded_model, eval_data, claude_model_name) #added to the load and eval function, with name of Claude\n",
        "\n",
        "    mlflow.log_metric(\"mean_score\", results[\"score\"]) # Log a metric value\n",
        "    print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during the MLflow run: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486,
          "referenced_widgets": [
            "c247ccb1100b446e8bb705ef2965d877",
            "0e1c1ff7779d49939608df43e7bcbd3d",
            "62c280ff44cf4315a0b79972a0715c46",
            "d529448386dd4e8ab366cbe788252ba9",
            "21addd8116fa4296b3a213491027318a",
            "2ba159a319394da391252c21c3c69ed5",
            "acf261c4e3fc4bc6b8157b46c5c70b74",
            "54eef8d460bd4615b23fb29850cbdbf7",
            "e7551cce026246ab9bfb6a2f7da20c0b",
            "199d5755eb6e4708ad1ca40f9e9b47be",
            "eaaf7ba6eda74c2b9e0fbe2f28e29438"
          ]
        },
        "id": "_2KxcYFlNx7-",
        "outputId": "f82559db-c08b-404e-d32e-83738f64c8e5"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "import anthropic\n",
        "import os\n",
        "\n",
        "# 2. Set Your Anthropic API Key (Replace with your actual key!)\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\" # Replace!\n",
        "\n",
        "# 3. Configuration\n",
        "# 4. Define your model run ID\n",
        "model_run_id = \"58868c4b1e1a424d9fb7433a76f2ac0d\" # Fill the run of an older saved model!\n",
        "\n",
        "# Set your model and experiment name\n",
        "claude_model_name = \"claude-3-opus-20240229\" # @param {type:\"string\"}\n",
        "MLFLOW_EXPERIMENT_NAME = \"claude_wrapping\" # @param {type:\"string\"}\n",
        "\n",
        "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
        "\n",
        "# Check is the api key is accesible\n",
        "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
        "  raise ValueError(\"Anthropic API key not found. Set ANTHROPIC_API_KEY environment variable.\")\n",
        "\n",
        "# 5. Load the Model (Replace with the correct Model URI)\n",
        "model_uri = 'runs:/58868c4b1e1a424d9fb7433a76f2ac0d/claude_model'\n",
        "loaded_model = mlflow.pyfunc.load_model(model_uri) # Load only once, to save in the test.\n",
        "\n",
        "# 6. Define the evaluation Function\n",
        "def get_claude_judgment(question, answer, ground_truth, prompt, claude_model_id):\n",
        "  \"\"\"Calls Claude API for evaluation and returns a tuple (score, justification) or (1, \"Error\") on error.\"\"\"\n",
        "  try:\n",
        "      client = anthropic.Anthropic()\n",
        "      message = client.messages.create(\n",
        "          model=claude_model_id,\n",
        "          max_tokens=300,\n",
        "          system=prompt,\n",
        "          messages=[{\"role\": \"user\", \"content\": f\"Question: {question}\\nAnswer: {answer}\\nGround Truth: {ground_truth}\"}],\n",
        "      )\n",
        "      claude_response = message.content[0].text\n",
        "      try:  # Safely extract score and justification\n",
        "          score = int(claude_response.split()[0])\n",
        "          justification = \" \".join(claude_response.split()[1:])\n",
        "          return score, justification\n",
        "      except (ValueError, IndexError):\n",
        "          print(f\"Could not parse Claude's response: {claude_response}\")  # More specific message\n",
        "          return 1, \"Could not parse Claude's response.\"\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Error calling Claude API: {e}\")\n",
        "      return 1, \"Error during evaluation.\"  # Consistent return\n",
        "\n",
        "\n",
        "# 7. Load and eval\n",
        "def claude_evaluate(eval_data, claude_model_name, loaded_model):\n",
        "\n",
        "    question = eval_data[\"question\"].tolist()\n",
        "    ground_truth = eval_data[\"ground_truth\"].tolist()\n",
        "    scores = []\n",
        "    justifications = []\n",
        "\n",
        "    #Here I use the Claude Directly and No call the previous functions, so there will be no issue\n",
        "    for index in range(len(eval_data)):\n",
        "\n",
        "        client = anthropic.Anthropic() #Using this fixes the issues!\n",
        "        try:\n",
        "          message = client.messages.create(\n",
        "              model=claude_model_name,\n",
        "              max_tokens=1024,\n",
        "              system = \"You will evaluate the answer based on the Ground Turth\",\n",
        "              messages=[\n",
        "                  {\"role\": \"user\", \"content\": f\"Question: {question[index]}\\n Ground Truth:{ground_truth[index]}\"} # Now the System Role is at the top\n",
        "              ],\n",
        "          )\n",
        "          #After having the model, you can get the proper judgement\n",
        "\n",
        "          score, justification = get_claude_judgment(question = question[index], answer = message.content[0].text, ground_truth = ground_truth[index], prompt = \"You will score from 1 to 5 the answer, comparing it with the Ground Truth\", claude_model_id = claude_model_name)\n",
        "          scores.append(score)\n",
        "          justifications.append(justification)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Claude API: {e}\")\n",
        "            score = 1 #Put the lowest score in case of failure\n",
        "            justification = \"Failure from the bot\"\n",
        "            scores.append(score)\n",
        "            justifications.append(justification)\n",
        "\n",
        "    result = sum(scores)/len(scores) #Just compute the final score\n",
        "    print(f\"Justifications: {justifications}\")\n",
        "\n",
        "    return {\"score\":result}\n",
        "\n",
        "# 8. Define Evaluation Data\n",
        "eval_data = pd.DataFrame({\n",
        "    \"question\": [\n",
        "        \"What is MLflow?\",\n",
        "        \"What is Spark?\",\n",
        "    ],\n",
        "    \"ground_truth\": [\n",
        "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle.\",\n",
        "        \"Apache Spark is a fast, general-purpose cluster computing system for big data processing.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "try:\n",
        "  with mlflow.start_run() as run: #Create a run for this\n",
        "    results = claude_evaluate(eval_data, claude_model_name, loaded_model) #Just need to load\n",
        "\n",
        "    mlflow.log_metric(\"mean_score\", results[\"score\"]) #Log a metric value\n",
        "    print(f\"Evaluation Results: {results}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during the MLflow run: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8btacFORWr6",
        "outputId": "fb57bc9c-f3fb-4ceb-e410-243281447bb8"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow anthropic pandas textstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "101rGEmiRZr6",
        "outputId": "2c21f913-82ae-4f75-8093-602967815838"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import os\n",
        "from typing import List\n",
        "import textstat  # For readability metrics\n",
        "\n",
        "# 1. Set Your Anthropic API Key\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"  # Replace!\n",
        "\n",
        "# 2. Define Evaluation Data\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "        \"ground_truth\": [\n",
        "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is designed to address the challenges that data scientists and machine learning engineers face when developing, training, and deploying machine learning models.\",\n",
        "            \"Apache Spark is an open-source, distributed computing system designed for big data processing and analytics. It was developed in response to limitations of the Hadoop MapReduce computing model, offering improvements in speed and ease of use. Spark provides libraries for various tasks such as data ingestion, processing, and analysis through its components like Spark SQL for structured data, Spark Streaming for real-time data processing, and MLlib for machine learning tasks\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define the Claude Model Function\n",
        "def anthropic_qa(inputs: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generates responses using the Anthropic Claude API.\n",
        "\n",
        "    Args:\n",
        "        inputs: A Pandas DataFrame with an 'inputs' column containing prompts.\n",
        "\n",
        "    Returns:\n",
        "        A list of Claude's responses.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    system_prompt = \"Please answer the following question in formal language.\"\n",
        "    client = anthropic.Anthropic()\n",
        "\n",
        "    for _, row in inputs.iterrows():\n",
        "        try:\n",
        "            message = client.messages.create(\n",
        "                model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "                max_tokens=1024,\n",
        "                system= system_prompt,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": row[\"inputs\"]},\n",
        "                ],\n",
        "            )\n",
        "            predictions.append(message.content[0].text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Claude API: {e}\")\n",
        "            predictions.append(None)  # Or a suitable error value\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# 4. Define the all the custom metric in just a func\n",
        "def calculate_metrics(df):\n",
        "\n",
        "  flesch_kincaid_grade_levels = []\n",
        "  ari_grade_levels = []\n",
        "  exact_matches = []\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "        # Readability metrics\n",
        "        flesch_kincaid_grade_level = textstat.flesch_kincaid_grade(row[\"predictions\"])\n",
        "        ari_grade_level = textstat.automated_readability_index(row[\"predictions\"])\n",
        "\n",
        "        flesch_kincaid_grade_levels.append(flesch_kincaid_grade_level)\n",
        "        ari_grade_levels.append(ari_grade_level)\n",
        "\n",
        "        # Exact match (basic, case-insensitive)\n",
        "        exact_match = 1.0 if row[\"ground_truth\"].lower() == row[\"predictions\"].lower() else 0.0\n",
        "        exact_matches.append(exact_match)\n",
        "\n",
        "  # Compute the mean, variance, and 90th percentile using list comprehensions\n",
        "  flesch_kincaid_grade_level_mean = sum(flesch_kincaid_grade_levels) / len(flesch_kincaid_grade_levels)\n",
        "  flesch_kincaid_grade_level_variance = sum([(x - flesch_kincaid_grade_level_mean) ** 2 for x in flesch_kincaid_grade_levels]) / len(flesch_kincaid_grade_levels) # Compute unbiased Variance\n",
        "  flesch_kincaid_grade_level_p90 = sorted(flesch_kincaid_grade_levels)[int(0.9 * len(flesch_kincaid_grade_levels))]\n",
        "\n",
        "  ari_grade_level_mean = sum(ari_grade_levels) / len(ari_grade_levels)\n",
        "  ari_grade_level_variance = sum([(x - ari_grade_level_mean) ** 2 for x in ari_grade_levels]) / len(ari_grade_levels) # Compute unbiased Variance\n",
        "  ari_grade_level_p90 = sorted(ari_grade_levels)[int(0.9 * len(ari_grade_levels))]\n",
        "\n",
        "  exact_match_mean = sum(exact_matches) / len(exact_matches)\n",
        "\n",
        "  return {\n",
        "          \"flesch_kincaid_grade_level/v1/mean\": flesch_kincaid_grade_level_mean,\n",
        "          \"flesch_kincaid_grade_level/v1/variance\": flesch_kincaid_grade_level_variance,\n",
        "          \"flesch_kincaid_grade_level/v1/p90\": flesch_kincaid_grade_level_p90,\n",
        "          \"ari_grade_level/v1/mean\": ari_grade_level_mean,\n",
        "          \"ari_grade_level/v1/variance\": ari_grade_level_variance,\n",
        "          \"ari_grade_level/v1/p90\": ari_grade_level_p90,\n",
        "          \"exact_match/v1\": exact_match_mean\n",
        "      }\n",
        "\n",
        "# 5. Run the evaluation\n",
        "with mlflow.start_run():\n",
        "    # Generate Claude model outputs\n",
        "    predictions = anthropic_qa(eval_data)\n",
        "    eval_data[\"predictions\"] = predictions\n",
        "\n",
        "    metrics = calculate_metrics(eval_data) # Calculate the metrics on the new predictions\n",
        "\n",
        "    # Log results\n",
        "    mlflow.log_metrics(metrics)\n",
        "\n",
        "    print(f\"Metrics: {metrics}\")\n",
        "    print(eval_data)  # Display the dataframe with the responses and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE2Qmz6LSj2X",
        "outputId": "1f1519b7-19c0-43c4-9ceb-57eaa88052c8"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import os\n",
        "from typing import List\n",
        "import textstat  # For readability metrics\n",
        "import re\n",
        "\n",
        "# 1. Set Your Anthropic API Key\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"  # Replace!\n",
        "\n",
        "# 2. Define Evaluation Data\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "        \"ground_truth\": [\n",
        "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is designed to address the challenges that data scientists and machine learning engineers face when developing, training, and deploying machine learning models.\",\n",
        "            \"Apache Spark is an open-source, distributed computing system designed for big data processing and analytics. It was developed in response to limitations of the Hadoop MapReduce computing model, offering improvements in speed and ease of use. Spark provides libraries for various tasks such as data ingestion, processing, and analysis through its components like Spark SQL for structured data, Spark Streaming for real-time data processing, and MLlib for machine learning tasks\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define the Claude Model Function\n",
        "def anthropic_qa(inputs: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generates responses using the Anthropic Claude API.\n",
        "\n",
        "    Args:\n",
        "        inputs: A Pandas DataFrame with an 'inputs' column containing prompts.\n",
        "\n",
        "    Returns:\n",
        "        A list of Claude's responses.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    system_prompt = \"Please answer the following question in formal language.\"\n",
        "    client = anthropic.Anthropic()\n",
        "\n",
        "    for _, row in inputs.iterrows():\n",
        "        try:\n",
        "            message = client.messages.create(\n",
        "                model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "                max_tokens=1024,\n",
        "                system= system_prompt,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": row[\"inputs\"]},\n",
        "                ],\n",
        "            )\n",
        "            predictions.append(message.content[0].text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Claude API: {e}\")\n",
        "            predictions.append(None)  # Or a suitable error value\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# 4. Define the all the custom metric in just a func\n",
        "def calculate_metrics(df):\n",
        "\n",
        "  flesch_kincaid_grade_levels = []\n",
        "  ari_grade_levels = []\n",
        "  exact_matches = []\n",
        "\n",
        "  def normalize_text(text):\n",
        "      text = text.lower().strip()  # Convert to lowercase and remove whitespace\n",
        "      text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "      return text\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "        # Readability metrics\n",
        "        flesch_kincaid_grade_level = textstat.flesch_kincaid_grade(row[\"predictions\"])\n",
        "        ari_grade_level = textstat.automated_readability_index(row[\"predictions\"])\n",
        "\n",
        "        flesch_kincaid_grade_levels.append(flesch_kincaid_grade_level)\n",
        "        ari_grade_levels.append(ari_grade_level)\n",
        "\n",
        "        # Exact match (basic, case-insensitive)\n",
        "        normalized_ground_truth = normalize_text(row['ground_truth'])\n",
        "        normalized_prediction = normalize_text(row['predictions'])\n",
        "        exact_match = 1.0 if normalized_ground_truth == normalized_prediction else 0.0\n",
        "        exact_matches.append(exact_match)\n",
        "\n",
        "  # Compute the mean, variance, and 90th percentile using list comprehensions\n",
        "  flesch_kincaid_grade_level_mean = sum(flesch_kincaid_grade_levels) / len(flesch_kincaid_grade_levels)\n",
        "  flesch_kincaid_grade_level_variance = sum([(x - flesch_kincaid_grade_level_mean) ** 2 for x in flesch_kincaid_grade_levels]) / len(flesch_kincaid_grade_levels) # Compute unbiased Variance\n",
        "  flesch_kincaid_grade_level_p90 = sorted(flesch_kincaid_grade_levels)[int(0.9 * len(flesch_kincaid_grade_levels))]\n",
        "\n",
        "  ari_grade_level_mean = sum(ari_grade_levels) / len(ari_grade_levels)\n",
        "  ari_grade_level_variance = sum([(x - ari_grade_level_mean) ** 2 for x in ari_grade_levels]) / len(ari_grade_levels) # Compute unbiased Variance\n",
        "  ari_grade_level_p90 = sorted(ari_grade_levels)[int(0.9 * len(ari_grade_levels))]\n",
        "\n",
        "  exact_match_mean = sum(exact_matches) / len(exact_matches)\n",
        "\n",
        "  return {\n",
        "          \"flesch_kincaid_grade_level/v1/mean\": flesch_kincaid_grade_level_mean,\n",
        "          \"flesch_kincaid_grade_level/v1/variance\": flesch_kincaid_grade_level_variance,\n",
        "          \"flesch_kincaid_grade_level/v1/p90\": flesch_kincaid_grade_level_p90,\n",
        "          \"ari_grade_level/v1/mean\": ari_grade_level_mean,\n",
        "          \"ari_grade_level/v1/variance\": ari_grade_level_variance,\n",
        "          \"ari_grade_level/v1/p90\": ari_grade_level_p90,\n",
        "          \"exact_match/v1\": exact_match_mean\n",
        "      }\n",
        "\n",
        "# 5. Run the evaluation\n",
        "with mlflow.start_run():\n",
        "    # Generate Claude model outputs\n",
        "    predictions = anthropic_qa(eval_data)\n",
        "    eval_data[\"predictions\"] = predictions\n",
        "\n",
        "    metrics = calculate_metrics(eval_data)  # Calculate the metrics on the new predictions\n",
        "\n",
        "    # Log results\n",
        "    mlflow.log_metrics(metrics)\n",
        "\n",
        "    print(f\"Metrics: {metrics}\")\n",
        "    print(eval_data)  # Display the dataframe with the responses and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcRP5BnxbwQe",
        "outputId": "ca310c7a-26a1-4960-8826-902be8732ef3"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "from mlflow.metrics import make_metric\n",
        "\n",
        "# 1. Define Evaluation Data (with pre-computed predictions)\n",
        "eval_data = pd.DataFrame({\n",
        "    \"inputs\": [\n",
        "        \"What is MLflow?\",\n",
        "        \"What is Spark?\",\n",
        "    ],\n",
        "    \"ground_truth\": [\n",
        "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle.\",\n",
        "        \"Apache Spark is a fast, general-purpose cluster computing system for big data processing.\"\n",
        "    ],\n",
        "    \"predictions\": [ # Model is not run, so you need to load the answers into the model output\n",
        "        \"MLflow is a platform for managing the ML lifecycle.\",\n",
        "        \"Spark is a fast, general-purpose cluster computing system.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# 2. Create a simple, basic metrics\n",
        "def simple_metric(row):\n",
        "        if row[\"ground_truth\"].lower() in row[\"predictions\"].lower(): # comparing if the ground_truth is in the response\n",
        "            return 1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "# 3. Start MLflow and make the evaluation\n",
        "with mlflow.start_run() as run:\n",
        "    eval_data[\"metric\"] = eval_data.apply(simple_metric, axis=1)  # Apply the metric to each row\n",
        "    average_metric = eval_data[\"metric\"].mean()  # calculate the average of the metric\n",
        "\n",
        "    # Log results\n",
        "    mlflow.log_metric(\"simple_matching_accuracy\", average_metric) # Log the simple matching accuracy\n",
        "    print(f\"Simple Matching Accuracy: {average_metric}\")\n",
        "\n",
        "    print(eval_data)  # Display the dataframe with the responses and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8zrblPsfUj8",
        "outputId": "ff6f6f6a-9bf8-4e68-e1d4-725f4c121af9"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import os\n",
        "from typing import List\n",
        "import textstat  # For readability metrics\n",
        "import re\n",
        "from mlflow.data import from_pandas\n",
        "import tempfile #Import temporal directory\n",
        "\n",
        "# 1. Set Your Anthropic API Key\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"  # Replace!\n",
        "\n",
        "# 2. Define Evaluation Data\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "        \"ground_truth\": [\n",
        "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is designed to address the challenges that data scientists and machine learning engineers face when developing, training, and deploying machine learning models.\",\n",
        "            \"Apache Spark is an open-source, distributed computing system designed for big data processing and analytics. It was developed in response to limitations of the Hadoop MapReduce computing model, offering improvements in speed and ease of use. Spark provides libraries for various tasks such as data ingestion, processing, and analysis through its components like Spark SQL for structured data, Spark Streaming for real-time data processing, and MLlib for machine learning tasks\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define the Claude Model Function\n",
        "def anthropic_qa(inputs: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generates responses using the Anthropic Claude API.\n",
        "\n",
        "    Args:\n",
        "        inputs: A Pandas DataFrame with an 'inputs' column containing prompts.\n",
        "\n",
        "    Returns:\n",
        "        A list of Claude's responses.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    system_prompt = \"Please answer the following question in formal language.\"\n",
        "    client = anthropic.Anthropic()\n",
        "\n",
        "    for _, row in inputs.iterrows():\n",
        "        try:\n",
        "            message = client.messages.create(\n",
        "                model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "                max_tokens=1024,\n",
        "                system= system_prompt,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": row[\"inputs\"]},\n",
        "                ],\n",
        "            )\n",
        "            predictions.append(message.content[0].text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Claude API: {e}\")\n",
        "            predictions.append(None)  # Or a suitable error value\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# 4. Define the all the custom metric in just a func\n",
        "def calculate_metrics(df):\n",
        "\n",
        "  flesch_kincaid_grade_levels = []\n",
        "  ari_grade_levels = []\n",
        "  exact_matches = []\n",
        "\n",
        "  def normalize_text(text):\n",
        "      text = text.lower().strip()  # Convert to lowercase and remove whitespace\n",
        "      text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "      return text\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "        # Readability metrics\n",
        "        flesch_kincaid_grade_level = textstat.flesch_kincaid_grade(row[\"predictions\"])\n",
        "        ari_grade_level = textstat.automated_readability_index(row[\"predictions\"])\n",
        "\n",
        "        flesch_kincaid_grade_levels.append(flesch_kincaid_grade_level)\n",
        "        ari_grade_levels.append(ari_grade_level)\n",
        "\n",
        "        # Exact match (basic, case-insensitive)\n",
        "        normalized_ground_truth = normalize_text(row['ground_truth'])\n",
        "        normalized_prediction = normalize_text(row['predictions'])\n",
        "        exact_match = 1.0 if normalized_ground_truth == normalized_prediction else 0.0\n",
        "        exact_matches.append(exact_match)\n",
        "\n",
        "  # Compute the mean, variance, and 90th percentile using list comprehensions\n",
        "  flesch_kincaid_grade_level_mean = sum(flesch_kincaid_grade_levels) / len(flesch_kincaid_grade_levels)\n",
        "  flesch_kincaid_grade_level_variance = sum([(x - flesch_kincaid_grade_level_mean) ** 2 for x in flesch_kincaid_grade_levels]) / len(flesch_kincaid_grade_levels) # Compute unbiased Variance\n",
        "  flesch_kincaid_grade_level_p90 = sorted(flesch_kincaid_grade_levels)[int(0.9 * len(flesch_kincaid_grade_levels))]\n",
        "\n",
        "  ari_grade_level_mean = sum(ari_grade_levels) / len(ari_grade_levels)\n",
        "  ari_grade_level_variance = sum([(x - ari_grade_level_mean) ** 2 for x in ari_grade_levels]) / len(ari_grade_levels) # Compute unbiased Variance\n",
        "  ari_grade_level_p90 = sorted(ari_grade_levels)[int(0.9 * len(ari_grade_levels))]\n",
        "\n",
        "  exact_match_mean = sum(exact_matches) / len(exact_matches)\n",
        "\n",
        "  return {\n",
        "          \"flesch_kincaid_grade_level/v1/mean\": flesch_kincaid_grade_level_mean,\n",
        "          \"flesch_kincaid_grade_level/v1/variance\": flesch_kincaid_grade_level_variance,\n",
        "          \"flesch_kincaid_grade_level/v1/p90\": flesch_kincaid_grade_level_p90,\n",
        "          \"ari_grade_level/v1/mean\": ari_grade_level_mean,\n",
        "          \"ari_grade_level/v1/variance\": ari_grade_level_variance,\n",
        "          \"ari_grade_level/v1/p90\": ari_grade_level_p90,\n",
        "          \"exact_match/v1\": exact_match_mean\n",
        "      }\n",
        "\n",
        "# 5. Run the evaluation\n",
        "with mlflow.start_run() as run:\n",
        "    # Generate Claude model outputs\n",
        "    predictions = anthropic_qa(eval_data)\n",
        "    eval_data[\"predictions\"] = predictions\n",
        "\n",
        "    metrics = calculate_metrics(eval_data)  # Calculate the metrics on the new predictions\n",
        "\n",
        "    # Log results\n",
        "    mlflow.log_metrics(metrics)\n",
        "\n",
        "    print(f\"Metrics: {metrics}\")\n",
        "    print(eval_data)  # Display the dataframe with the responses and metrics\n",
        "# Temp csv save + upload\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        csv_path = os.path.join(tmpdir, \"eval_results.csv\")\n",
        "        eval_data.to_csv(csv_path, index=False)  # Save without index\n",
        "        mlflow.log_artifact(csv_path, artifact_path=\"eval_results_table\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "072421e892194abfa85cfb1995076ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a1a68e5be33489a97408df998715056",
            "placeholder": "​",
            "style": "IPY_MODEL_88f81ad09ab1475db5197d93babd41ba",
            "value": "Downloading artifacts: 100%"
          }
        },
        "0e1c1ff7779d49939608df43e7bcbd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba159a319394da391252c21c3c69ed5",
            "placeholder": "​",
            "style": "IPY_MODEL_acf261c4e3fc4bc6b8157b46c5c70b74",
            "value": "Downloading artifacts: 100%"
          }
        },
        "19048e71f5b145da8c401ab385531440": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199d5755eb6e4708ad1ca40f9e9b47be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21addd8116fa4296b3a213491027318a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2accc7cc15c440f8971532206d17dbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ba159a319394da391252c21c3c69ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5122d9709c294b7191e81fd8d344448a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54eef8d460bd4615b23fb29850cbdbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c0fb845c473469b8511494888e03e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19048e71f5b145da8c401ab385531440",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4536cfa5b9b4947b59dee5ee22bf4d5",
            "value": 8
          }
        },
        "62c280ff44cf4315a0b79972a0715c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54eef8d460bd4615b23fb29850cbdbf7",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7551cce026246ab9bfb6a2f7da20c0b",
            "value": 8
          }
        },
        "6a1a68e5be33489a97408df998715056": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5a5ee2a58344d3a26b1c7b0aa4ca0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88f81ad09ab1475db5197d93babd41ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a95ffefc431349bdb9e1ee3e045d332a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_072421e892194abfa85cfb1995076ff3",
              "IPY_MODEL_5c0fb845c473469b8511494888e03e71",
              "IPY_MODEL_ac13c74a8fd94aa6a7dd110325daafc6"
            ],
            "layout": "IPY_MODEL_7c5a5ee2a58344d3a26b1c7b0aa4ca0b"
          }
        },
        "ac13c74a8fd94aa6a7dd110325daafc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5122d9709c294b7191e81fd8d344448a",
            "placeholder": "​",
            "style": "IPY_MODEL_2accc7cc15c440f8971532206d17dbc9",
            "value": " 8/8 [00:00&lt;00:00, 36.91it/s]"
          }
        },
        "acf261c4e3fc4bc6b8157b46c5c70b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4536cfa5b9b4947b59dee5ee22bf4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c247ccb1100b446e8bb705ef2965d877": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e1c1ff7779d49939608df43e7bcbd3d",
              "IPY_MODEL_62c280ff44cf4315a0b79972a0715c46",
              "IPY_MODEL_d529448386dd4e8ab366cbe788252ba9"
            ],
            "layout": "IPY_MODEL_21addd8116fa4296b3a213491027318a"
          }
        },
        "d529448386dd4e8ab366cbe788252ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_199d5755eb6e4708ad1ca40f9e9b47be",
            "placeholder": "​",
            "style": "IPY_MODEL_eaaf7ba6eda74c2b9e0fbe2f28e29438",
            "value": " 8/8 [00:00&lt;00:00, 16.58it/s]"
          }
        },
        "e7551cce026246ab9bfb6a2f7da20c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaaf7ba6eda74c2b9e0fbe2f28e29438": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
